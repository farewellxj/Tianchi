{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from scipy import sparse\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pylab as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('jinnan_round1_train_20181227.csv',encoding='gbk')\n",
    "test = pd.read_csv('jinnan_round1_testA_20181227.csv',encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除缺失率超过90%的列\n",
    "good_cols = list(train.columns)\n",
    "for col in train.columns:\n",
    "    rate = train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if rate > 0.9:\n",
    "        good_cols.remove(col)\n",
    "\n",
    "# 删除异常值\n",
    "train = train[train['收率']>0.87]\n",
    "        \n",
    "train = train[good_cols]\n",
    "good_cols.remove('收率')\n",
    "test  = test[good_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['收率']\n",
    "del train['收率']\n",
    "data = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "data = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeTranSecond(t):\n",
    "    try:\n",
    "        t,m,s=t.split(\":\")\n",
    "    except:\n",
    "        if t=='1900/1/9 7:00':\n",
    "            return 7*3600/3600\n",
    "        elif t=='1900/1/1 2:30':\n",
    "            return (2*3600+30*60)/3600\n",
    "        elif t==-1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    try:\n",
    "        tm = (int(t)*3600+int(m)*60+int(s))/3600\n",
    "    except:\n",
    "        return (30*60)/3600\n",
    "    \n",
    "    return tm\n",
    "for f in ['A5','A7','A9','A11','A14','A16','A24','A26','B5','B7']:\n",
    "    data[f] = data[f].apply(timeTranSecond)\n",
    "\n",
    "def getDuration(se):\n",
    "    try:\n",
    "        sh,sm,eh,em=re.findall(r\"\\d+\\.?\\d*\",se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1 \n",
    "        \n",
    "    try:\n",
    "        if int(sh)>int(eh):\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600 + 24\n",
    "        else:\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600\n",
    "    except:\n",
    "        if se=='19:-20:05':\n",
    "            return 1\n",
    "        elif se=='15:00-1600':\n",
    "            return 1\n",
    "    \n",
    "    return tm\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f] = data.apply(lambda df: getDuration(df[f]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_columns = [f for f in data.columns if f != '样本id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in cate_columns:\n",
    "    data[f] = data[f].map(dict(zip(data[f].unique(), range(0, data[f].nunique()))))\n",
    "train = data[:train.shape[0]]\n",
    "test  = data[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = target\n",
    "train['intTarget'] = pd.cut(train['target'], 5, labels=False)\n",
    "train = pd.get_dummies(train, columns=['intTarget'])\n",
    "li = ['intTarget_0.0','intTarget_1.0','intTarget_2.0','intTarget_3.0','intTarget_4.0']\n",
    "mean_features = []\n",
    "\n",
    "for f1 in cate_columns:\n",
    "    for f2 in li:\n",
    "        col_name = f1+\"_\"+f2+'_mean'\n",
    "        mean_features.append(col_name)\n",
    "        order_label = train.groupby([f1])[f2].mean()\n",
    "        for df in [train, test]:\n",
    "            df[col_name] = df[f].map(order_label) # 正是此处逻辑错误\n",
    "\n",
    "train.drop(li, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = train.drop(['样本id','target'], axis=1)\n",
    "test = test[train_2.columns]\n",
    "X_train = train_2.values\n",
    "Y_train = target.values\n",
    "X_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1381,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1381, 192)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1381, 192)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_data = pd.DataFrame(X_train)\n",
    "Z_data = Z_data.fillna('0')\n",
    "#Z_data = Z_data.convert_objects(convert_numeric=True)\n",
    "Z_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(Z_data,Y_train,train_size = 0.8,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 trainings, the cost: 4.464980\n",
      "RMSE：0.927552\n",
      "After 400 trainings, the cost: 0.274762\n",
      "RMSE：0.163742\n",
      "After 800 trainings, the cost: 0.162563\n",
      "RMSE：0.094828\n",
      "After 1200 trainings, the cost: 0.119484\n",
      "RMSE：0.067119\n",
      "After 1600 trainings, the cost: 0.093837\n",
      "RMSE：0.051411\n",
      "After 2000 trainings, the cost: 0.072791\n",
      "RMSE：0.041321\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation ,Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100,input_dim=192))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "          \n",
    "sgd = SGD(lr=0.0005)\n",
    "model.compile(loss='mse',\n",
    "              optimizer=sgd,\n",
    "              metrics=['mse'])\n",
    "\n",
    "for step in range(2001):\n",
    "    cost = model.train_on_batch(x_train, y_train)\n",
    "    if step % 400 == 0:\n",
    "        print(\"After %d trainings, the cost: %f\" % (step, cost[0]))\n",
    "        print('RMSE：%f' % mean_squared_error(y_test,model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用CV对以下几个模型作改良**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = cross_validation.KFold(len(Z_data), n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r f：0.000166\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators= 50, max_depth=20, min_samples_split=10,\n",
    "                                  min_samples_leaf=3,max_features='sqrt' ,oob_score=True, random_state=10).fit(x_train,y_train)\n",
    "print('r f：%f' % mean_squared_error(y_test,rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00020545, -0.00019516, -0.00019057])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation.cross_val_score(rf, Z_data, Y_train, n_jobs=-1,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bdt: 0.000184 \n"
     ]
    }
   ],
   "source": [
    "bdt = AdaBoostRegressor(DecisionTreeRegressor(max_depth=30, min_samples_split=15, min_samples_leaf=10,criterion='mse'),loss='square',\n",
    "                         n_estimators=20, learning_rate=0.01)\n",
    "bdt.fit(x_train,y_train)\n",
    "print('bdt: %.6f '%mean_squared_error(y_test,bdt.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00021037, -0.00021701, -0.00018989])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation.cross_val_score(bdt, Z_data, Y_train, n_jobs=-1,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm: 0.000170\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingRegressor(learning_rate=0.05, n_estimators=50,max_depth=20, min_samples_leaf =10, \n",
    "                                min_samples_split =8, max_features='sqrt', subsample=0.9, random_state=10)\n",
    "\n",
    "gbm.fit(x_train,y_train)\n",
    "print('gbm: %.6f' %mean_squared_error(y_test,gbm.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00020685, -0.00019559, -0.00019638])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation.cross_val_score(gbm, Z_data, Y_train, n_jobs=-1,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(Z_data,Y_train,train_size = 0.5,random_state=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31532057 0.38181265 0.30986591] -0.006505678738667253\n",
      "0.00014349832290817024\n"
     ]
    }
   ],
   "source": [
    "stack = pd.DataFrame()\n",
    "\n",
    "stack['rf'] = rf.predict(x_test)\n",
    "stack['bdt'] = bdt.predict(x_test)\n",
    "stack['gbm'] = gbm.predict(x_test)\n",
    "#############################################\n",
    "\n",
    "rg = RidgeCV(cv=5).fit(stack,y_test)\n",
    "coefs = rg.coef_\n",
    "intercepts = rg.intercept_\n",
    "print(coefs,intercepts)\n",
    "print(mean_squared_error(y_test,rg.predict(stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = pd.DataFrame(X_test).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved!\n"
     ]
    }
   ],
   "source": [
    "FFF['rf'] = rf.predict(X_test1)\n",
    "FFF['bdt'] = bdt.predict(X_test1)\n",
    "FFF['gbm'] = gbm.predict(X_test1)\n",
    "\n",
    "finals = rg.predict(FFF)\n",
    "\n",
    "commit = pd.DataFrame()\n",
    "commit['result'] = finals\n",
    "commit = commit.apply(lambda x:round(x,3))\n",
    "commit.to_csv('fff.csv',header=None,index=False)\n",
    "\n",
    "print('file saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
